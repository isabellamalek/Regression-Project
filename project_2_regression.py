# -*- coding: utf-8 -*-
"""Project 2- Regression

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JZoJyFzPYW2Bd76LuwbZeXB5vNHCV65w
"""

#import data frame
import pandas as pd
import seaborn as sb
import matplotlib.pyplot as plt

df = pd.read_csv('/content/student-scores.csv')
display(df)

#load columns into lists

math = df['math_score']
history = df['history_score']
physics = df['physics_score']
chemistry = df['chemistry_score']
biology = df['biology_score']
english = df['english_score']
geography = df['geography_score']

print(math, history, physics, chemistry, biology, english, geography)

#add new column with averages
averages = []

for i in range(2000):
  sum = math[i] + history[i] + physics[i] + chemistry[i] + biology[i] + english[i] + geography[i]
  score = sum // 7
  averages.append(score)


print(averages)
print(len(averages))

#adding in averages column

df['average_scores'] = averages

display(df)

#drop columns

altered_df = df.drop(labels=['first_name', 'last_name','email', 'gender', 'math_score', 'history_score', 'physics_score', 'chemistry_score', 'biology_score', 'english_score', 'geography_score'], axis = 1)
display(altered_df)

#creating dummy variables

#part time job to binary
part_time_binary = []
for i in altered_df['part_time_job']:
  if i == True:
    part_time_binary.append(1)
  else:
    part_time_binary.append(0)

print(part_time_binary)


#extracuriculars to binary
ec_binary = []
for i in altered_df['extracurricular_activities']:
  if i == True:
    ec_binary.append(1)
  else:
    ec_binary.append(0)

print(ec_binary)

#load dummy variables in as new columns and drop old columns

altered_df['part_time_binary'] = part_time_binary
altered_df['ec_activities_binary'] = ec_binary

final_df = altered_df.drop(labels= ['part_time_job', 'extracurricular_activities'], axis = 1)
display(final_df)

#training and testing model

import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
import matplotlib.pyplot as plt

# Load  dataset into altered_df
# Assuming altered_df is already defined

# Define features (X) and target variable (y)
X = altered_df[['part_time_binary', 'absence_days', 'weekly_self_study_hours']].values
y = altered_df['average_scores'].values

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Create polynomial features
poly = PolynomialFeatures(degree=2)
train_X_poly = poly.fit_transform(X_train)
test_x_poly = poly.fit_transform(X_test)

# Model data
model = LinearRegression()
model.fit(train_X_poly, y_train)

# Run X_test through the model
y_pred = model.predict(test_x_poly)

# Evaluate the model
r_squared = r2_score(y_test, y_pred)
print('R-squared:', r_squared)

# Plot actual scores against predicted scores
plt.scatter(y_test, y_pred, color='fuchsia', label='Actual vs Predicted')
plt.title('Actual vs Predicted Scores')
plt.xlabel('Actual Scores')
plt.ylabel('Predicted Scores')
plt.legend()
plt.show()

#training model
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import r2_score
import matplotlib.pyplot as plt

# Load dataset into altered_df
# Assuming altered_df is already defined

# Define features (X) and target variable (y)
X = altered_df[['part_time_binary', 'absence_days', 'weekly_self_study_hours']].values
y = altered_df['average_scores'].values

# Use the first 75% of the data for training
split_index = int(0.75 * len(X))
X_train = X[:split_index]
y_train = y[:split_index]

# Create polynomial features
poly = PolynomialFeatures(degree=2)
train_X_poly = poly.fit_transform(X_train)

# Model data
model = LinearRegression()
model.fit(train_X_poly, y_train)

# Run X_train through the model
y_pred = model.predict(train_X_poly)

# Plot actual scores against predicted scores for training data
plt.scatter(y_train, y_pred, color='orange', label='Actual vs Predicted')
plt.title('Actual vs Predicted Scores for Training Data')
plt.xlabel('Actual Scores')
plt.ylabel('Predicted Scores')
plt.legend()
plt.show()

#testing model
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import r2_score
import matplotlib.pyplot as plt

# Load dataset into altered_df
# Assuming altered_df is already defined

# Define features (X) and target variable (y)
X = altered_df[['part_time_binary', 'absence_days', 'weekly_self_study_hours']].values
y = altered_df['average_scores'].values

# Use the first 75% of the data for training
split_index = int(0.75 * len(X))
X_train = X[:split_index]
y_train = y[:split_index]

# Use the last 25% of the data for testing
X_test = X[split_index:]
y_test = y[split_index:]

# Create polynomial features for training data
poly = PolynomialFeatures(degree=2)
train_X_poly = poly.fit_transform(X_train)

# Model training data
model = LinearRegression()
model.fit(train_X_poly, y_train)

# Run X_test through the model
test_X_poly = poly.transform(X_test)
y_pred = model.predict(test_X_poly)

# Evaluate the model using R-squared
r_squared = r2_score(y_test, y_pred)
print('R-squared:', r_squared)

# Plot actual scores against predicted scores for testing data
plt.scatter(y_test, y_pred, color='red', label='Actual vs Predicted', alpha=0.7)
plt.title('Actual vs Predicted Scores for Testing Data')
plt.xlabel('Actual Scores')
plt.ylabel('Predicted Scores')
plt.legend()
plt.show()

"""Model 1

"""